{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f83d920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x121801c70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3335591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d111839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# CIFAR-10の訓練用データセットを読み込み、\n",
    "# 以下の2つの前処理を適用する：\n",
    "# 1. ToTensor(): PIL画像をPyTorchのTensor形式に変換（ピクセル値を0〜1にスケーリング）\n",
    "# 2. Normalize(): 画像のRGBチャンネルごとに、訓練セット全体の平均と標準偏差を用いて正規化\n",
    "\n",
    "data_path = \"../data-unversioned/p1ch7/\"\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path,  # データを保存するディレクトリ\n",
    "    train=True,  # 訓練用データセットを指定\n",
    "    download=False,  # 既にダウンロード済みのため再取得しない\n",
    "    transform=transforms.Compose(\n",
    "        [  # 複数の変換を順に適用\n",
    "            transforms.ToTensor(),  # PIL → Tensor（float32, 範囲: 0〜1）\n",
    "            transforms.Normalize(  # チャンネルごとの正規化\n",
    "                (0.4915, 0.4823, 0.4468),  # 平均（R, G, B）\n",
    "                (0.2470, 0.2435, 0.2616),  # 標準偏差（R, G, B）\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85bcbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a51fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10の中から \"airplane\" (label=0) と \"bird\" (label=2) のみを抽出し、\n",
    "# ラベルを {0: 0, 2: 1} に変換して2クラス分類用のデータセットを作成する。\n",
    "\n",
    "label_map = {0: 0, 2: 1}  # 元のラベルを2クラス用にマッピング\n",
    "class_names = [\"airplane\", \"bird\"]  # 使用するクラス名\n",
    "\n",
    "# 訓練データから該当クラスのみを抽出し、ラベルを変換\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "\n",
    "# 検証データから該当クラスのみを抽出し、ラベルを変換\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c86460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-env)",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
